{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "805e4b5d-944b-44fc-b6b2-261f5f652ad9",
   "metadata": {},
   "source": [
    "# **BBM409 ASSIGNMENT 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabd68a-579f-481a-98b1-f730b07b9237",
   "metadata": {},
   "source": [
    "        Eylül TUNCEL - 21727801\n",
    "        Emre KÖSEN   - 21727498"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294e7a6-5e30-48b1-859b-20a6c4406c85",
   "metadata": {},
   "source": [
    "For this assignment, we implement a Neural Network and CNN to classify the examples on the Animal Classification Dataset mentioned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb1171-da46-4a7d-8dc3-9da22acb3ff3",
   "metadata": {},
   "source": [
    "## **PART 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fdc2d3-f434-4477-9241-b437a8b2bcef",
   "metadata": {},
   "source": [
    "Below you can see the implementation of our neural network. For Part 1, we implement changing layers of neural network and run experiments on Animal Classification Dataset. We changed parameters (activation func, learning rate, batch size) and put the results to the report.\n",
    "Changing parameters:\n",
    "* **Hidden Layer Count :** \n",
    "    * 0\n",
    "    * 1  \n",
    "    * 2 \n",
    "* **Activation Functions :** \n",
    "    * sigmoid\n",
    "    * tanh \n",
    "    * relu\n",
    "* **Batch Size :** \n",
    "    * 16\n",
    "    * 32\n",
    "    * 64 \n",
    "    * 128\n",
    "* **Learning rate :** \n",
    "    * 0.02\n",
    "    * 0.01 \n",
    "    * 0.005\n",
    "    \n",
    "As an inputs we gave all pixels of each images. Which means 2500 pixels are given as x0,x1,x2,..,x2500 as the input layer. We have 2500 neurons in the input layer.\n",
    "\n",
    "\n",
    "<img src=https://ml4a.github.io/images/figures/mnist_1layer.png width=\"300\"> <img src=https://ml4a.github.io/images/figures/weights_analogy_2.png width=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885e6bce-ec42-4e2a-b3c8-7dce31c76bf4",
   "metadata": {},
   "source": [
    "<img src=https://www.tibco.com/sites/tibco/files/media_entity/2021-05/neutral-network-diagram.svg width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de24bbb0-4a24-400c-bafd-b6c2a151403f",
   "metadata": {},
   "source": [
    "We give the changing parameters as a global variables to the functions. If you want to change some parameter, you should change it in the below code part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b81faa6-81d9-4169-98bf-0212a6ca6969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# pixel count in one side\n",
    "img_size = 50\n",
    "# total pixels in all input images (as features)\n",
    "n = img_size * img_size  \n",
    "c = 10  # number of classes\n",
    "\n",
    "# changing inputs given as global variables \n",
    "hidden_layer_count = 0\n",
    "learning_rate = 0.005\n",
    "epoch = 2\n",
    "batch_size = 128\n",
    "activation_func = \"sigmoid\"\n",
    "# activation_func = \"tan\"\n",
    "# activation_func = \"relu\"\n",
    "\n",
    "# calculate neuron size for each layer with code logic\n",
    "neuron_numbers = [n]  # as a start only input neurons are added \n",
    "\n",
    "# split the train-validation-test sets with those image counts\n",
    "# for a better split in numbers we choose (%78 train - %11 validation - %11 test)\n",
    "total_train_image_count = 20480\n",
    "total_validation_image_count = 2816\n",
    "total_test_image_count = 2816"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77245a6d-9432-417e-8967-42c93c26a98b",
   "metadata": {},
   "source": [
    "### **Initializing Parameters**\n",
    "Before starting to train our neural network, we should initialize some parameters like the neuron size of each layer and the initial weight/bias matrices for each layer.\n",
    "For choosing number of neurons in each layer we use this formula (we think fits best to our data): \n",
    "\n",
    "$\\sqrt{m+n}$ , where m=inout neurons, n=output neurons\n",
    "\n",
    "Initial weight matrix is generated with random numbers, and bias matrix generated with all zeros with respect to to the number of neurons in each layer.\n",
    "\n",
    "\n",
    "<img src=https://ml4a.github.io/images/figures/rolled_weights_mnist_0.png width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88fc8f9e-0c4a-465f-9701-29509ac58a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_parameters():\n",
    "    # parameters is the dictionary for weights and biases\n",
    "    parameters = {}\n",
    "    np.random.seed(101)\n",
    "\n",
    "    weight = []\n",
    "    bias = []\n",
    "\n",
    "    # initializing neuron numbers for each hidden layer by a formula given above\n",
    "    for i in range(hidden_layer_count):\n",
    "        x = round(math.sqrt(neuron_numbers[i] + c))\n",
    "        neuron_numbers.append(x)\n",
    "\n",
    "    # for each hidden layer there will be weights and biases connected that specific layer\n",
    "    for i in range(hidden_layer_count):\n",
    "        wei = np.random.randn(neuron_numbers[i + 1], neuron_numbers[i]) * 0.0001\n",
    "        bia = np.zeros((neuron_numbers[i + 1], 1))\n",
    "        weight.append(wei)\n",
    "        bias.append(bia)\n",
    "\n",
    "    wei = np.random.randn(c, neuron_numbers[hidden_layer_count]) * 0.0001\n",
    "    bia = np.zeros((c, 1))\n",
    "    weight.append(wei)\n",
    "    bias.append(bia)\n",
    "\n",
    "    parameters[\"w\"] = weight\n",
    "    parameters[\"b\"] = bias\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d34489-916b-437a-8de2-a154b0497e72",
   "metadata": {},
   "source": [
    "The datasets x and y are read from the pixels/images and creating an numpy array with the pixels. \n",
    "In x and y, every column represents an image. And batch size of images come together side by side to create x_train numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b589e94e-a038-4848-b5ea-8baa27a0ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train(data, x_train, y_train):\n",
    "    x_train = np.zeros((n, batch_size))\n",
    "    y_train = np.zeros((c, batch_size))\n",
    "\n",
    "    # initializing \n",
    "    for i in range(x_train.shape[0]):\n",
    "        for j in range(x_train.shape[1]):\n",
    "            x_train[i][j] = data[j][0][i]\n",
    "\n",
    "    for i in range(y_train.shape[1]):\n",
    "        class_index = data[i][1]\n",
    "        y_train[class_index][i] = 1\n",
    "\n",
    "    return x_train, y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2655574d-ba5f-4760-acaa-2a87776d5394",
   "metadata": {},
   "source": [
    "### **Activation Functions**\n",
    "\n",
    "1. **Sigmoid :**\n",
    "\n",
    "   Sigmoid function is known as the logistic function which helps to normalize the output of any input in the range between 0 to 1.  The sigmoid functions formula is : \n",
    "  \n",
    "    $y=\\frac{1}{1+ e^(-x)}$\n",
    "   \n",
    "   <img src=https://www.aitude.com/wp-content/uploads/2020/08/sigmoid.png width=300>\n",
    "2. **Tanh :**\n",
    "\n",
    "    Tanh Activation function is superior then the Sigmoid Activation function because the range of this activation function is higher than the sigmoid activation function. It ranges between -1 to 1.Here negative values are also considered.\n",
    "    \n",
    "   $y=tanh(x)$\n",
    "   \n",
    "    <img src=https://www.aitude.com/wp-content/uploads/2020/08/tanh-graph-aitude-768x423.png width=300>\n",
    "    \n",
    "3. **Relu :**\n",
    "\n",
    "    ReLu is the best and most advanced activation function right now compared to the sigmoid and TanH. Here all the negative values are converted into the 0 so there are no negative values are available, but positive values could go to infinity.\n",
    "    \n",
    "    $y=max(0,x)$\n",
    "    \n",
    "    <img src=https://www.aitude.com/wp-content/uploads/2020/08/relu-activation.png width=300>\n",
    "    \n",
    "\n",
    "4. **Softmax :**\n",
    "\n",
    "    The softmax activation function is for the output layer of the neural network. It’s commonly used in multi-class learning problems where a set of features can be related to one-of-K classes. The values of softmax ranges between 0 to 1.\n",
    "    \n",
    "    $y=\\frac{e^x}{\\sum{e^x}}$\n",
    "    \n",
    "    <img src=https://qph.fs.quoracdn.net/main-qimg-5c7cbb4b9fa300ac1de0f1dc3568fa3c width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1401fbed-daa0-4dd1-8e6a-1f1c14e5ff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def softmax(x):\n",
    "    expX = np.exp(x)\n",
    "    return expX / np.sum(expX, axis=0)\n",
    "\n",
    "def derivative_sigmoid(x):\n",
    "    return (1 / (1 + np.exp(-x))) * (1 - (1 / (1 + np.exp(-x))))\n",
    "\n",
    "def derivative_tanh(x):\n",
    "    return 1 - np.power(np.tanh(x), 2)\n",
    "\n",
    "def derivative_relu(x):\n",
    "    return np.array(x > 0, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a953a8-688e-4a19-a4e5-3786d98c2525",
   "metadata": {},
   "source": [
    "### **Forward Propagation**\n",
    "\n",
    "In forward propagation the input data is fed in the forward direction through the network. Each hidden layer accepts the input data, processes it as per the activation function and passes to the next layer.\n",
    "In forward propagation, firstly we have x matrix and parameters dictionary(which have weights and biases).\n",
    "In this part we need to calculate the numbers inside each neuron in each layer. For this purpose we use activation functions.The formula for calculatinons in each layer:\n",
    "\n",
    "$ Z_i = Weight_i * X_i + Bias_i $ \n",
    "\n",
    "\n",
    "$ A_i = activationFunction( Z_i ) $ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e43b619a-1b7e-4c89-8542-27dcf3cdaa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(x, parameters):\n",
    "    w = []\n",
    "    b = []\n",
    "    for i in range(hidden_layer_count + 1):\n",
    "        w.append(parameters['w'][i])\n",
    "        b.append(parameters['b'][i])\n",
    "\n",
    "    a = []\n",
    "    z = []\n",
    "    for i in range(hidden_layer_count + 1):\n",
    "        if i == 0:  # first\n",
    "            zi = np.dot(w[i], x) + b[i]\n",
    "            z.append(zi)\n",
    "        else:\n",
    "            zi = np.dot(w[i], a[i - 1]) + b[i]\n",
    "            z.append(zi)\n",
    "\n",
    "        if i == hidden_layer_count:  # last element\n",
    "            ai = softmax(zi)\n",
    "            a.append(ai)\n",
    "        else:\n",
    "            if activation_func == \"sigmoid\":\n",
    "                ai = sigmoid(zi)\n",
    "            elif activation_func == \"tan\":\n",
    "                ai = tanh(zi)\n",
    "            else:\n",
    "                ai = relu(zi)\n",
    "            a.append(ai)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6584435-2b98-4ac7-aba0-8ed5379afa8e",
   "metadata": {},
   "source": [
    "### **Loss Function**\n",
    "\n",
    "In our assignment, the loss function is \"Negative Log Likelihood\". In output layer, we have softmax as an activation function and it gives us probabilities of each class. In negative log likelihood loss function we take only the actual class's probability to calculate. And the cost is calculated by taking mean value of all the loss values in the batch. The formula of negative log likelihood is :\n",
    "\n",
    "$ Loss = - (log(P_i)) $ \n",
    "\n",
    "$ Cost =  \\frac{1}{m} * \\sum{Loss}$ \n",
    "\n",
    "<img src=https://ljvmiranda921.github.io/assets/png/cs231n-ann/neg_log.png width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82ef724e-3312-435c-b972-03482b1db376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(softmax_layer, y):\n",
    "    mx = y.shape[1]\n",
    "    loss = 0\n",
    "    for j in range(softmax_layer.shape[1]):\n",
    "        for i in range(softmax_layer.shape[0]):\n",
    "            if y[i][j] == 1:\n",
    "                probability = softmax_layer[i][j]\n",
    "                loss += (-(math.log(probability)))\n",
    "    cost = (1 / mx) * loss\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba78ab43-be4a-4e72-aa29-00229f25f6f9",
   "metadata": {},
   "source": [
    "### **Backward Propagation**\n",
    "\n",
    "Backward propagation refers to the method of calculating the gradient of neural network parameters. The method traverses the network in reverse order, from the output to the input layer, according to the chain rule from calculus. The algorithm stores any intermediate variables (partial derivatives) required while calculating the gradient with respect to some parameters. After the values are calculated, update all parameters with it to actually back propagate. With each batch, the weight of the each neuron changes according to the output and makes it creates the learning process. The calculations are as follows:\n",
    "\n",
    "* **For output layer (softmax):**\n",
    "\n",
    "$ Dz_i = DerivativeSoftmax(Z_i) = (A_p - Y) $\n",
    "\n",
    "* **For other layers:**\n",
    "\n",
    "$ Dz_i = W_2^T * Dz_p * derivative(Z_i) $\n",
    "\n",
    "* **The calculationf with derivatives:**\n",
    "\n",
    "$ Dw_i = \\frac{1}{m} * Dz_i * A_1^T$  \n",
    "\n",
    "$ Db_i = \\frac{1}{m} * sum(Dz_i ,1) $ \n",
    "\n",
    "$ W_i = W_i - (learning rate) * Dw_i $ \n",
    "\n",
    "$ B_i = B_i - (learning rate) * Db_i $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7029e36-d7aa-453c-8387-b4d925182518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_prop(x, y, parameters, forward_cache):\n",
    "    w = parameters[\"w\"].copy()\n",
    "    w.reverse()\n",
    "    a = forward_cache\n",
    "    a.reverse()\n",
    "    a.append(x)\n",
    "\n",
    "    dz = []\n",
    "    dw = []\n",
    "    db = []\n",
    "\n",
    "    m = batch_size\n",
    "\n",
    "    dz_output = (a[0] - y)\n",
    "    dw_output = (1 / m) * np.dot(dz_output, a[1].T)\n",
    "    db_output = (1 / m) * np.sum(dz_output, axis=1, keepdims=True)\n",
    "\n",
    "    dz.append(dz_output)\n",
    "    dw.append(dw_output)\n",
    "    db.append(db_output)\n",
    "\n",
    "    for i in range(hidden_layer_count):\n",
    "        if activation_func == \"sigmoid\":\n",
    "            dz_i = np.dot(w[i].T, dz[i]) * derivative_sigmoid(a[i + 1])\n",
    "        elif activation_func == \"tan\":\n",
    "            dz_i = np.dot(w[i].T, dz[i]) * derivative_tanh(a[i + 1])\n",
    "        else:\n",
    "            dz_i = np.dot(w[i].T, dz[i]) * derivative_relu(a[i + 1])\n",
    "        dw_i = (1 / m) * np.dot(dz_i, a[i + 2].T)\n",
    "        db_i = (1 / m) * np.sum(dz_i, axis=1, keepdims=True)\n",
    "        dz.append(dz_i)\n",
    "        dw.append(dw_i)\n",
    "        db.append(db_i)\n",
    "\n",
    "    dz.reverse()\n",
    "    dw.reverse()\n",
    "    db.reverse()\n",
    "\n",
    "    for i in range(hidden_layer_count + 1):\n",
    "        parameters['w'][i] = parameters['w'][i] - (learning_rate * dw[i])\n",
    "        parameters['b'][i] = parameters['b'][i] - (learning_rate * db[i])\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23b323f2-75d5-4d20-99ae-cd152dc18c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(softmax_layer, y):\n",
    "    true_count = 0\n",
    "    for j in range(softmax_layer.shape[1]):\n",
    "        max_prob = -1\n",
    "        index = -1\n",
    "        for i in range(softmax_layer.shape[0]):\n",
    "            if max_prob < softmax_layer[i][j]:\n",
    "                max_prob = softmax_layer[i][j]\n",
    "                index = i\n",
    "        if y[index][j] == 1:\n",
    "            true_count += 1\n",
    "    return true_count / softmax_layer.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194485dc-6526-4fe8-87e2-cb00e6936fb8",
   "metadata": {},
   "source": [
    "### **Visualizing Parameters**\n",
    "\n",
    "We visualize some weight matrices when the neural network is single layer. When there is single layer neural network, the weight matrices one side is equal to total input pixels. The shape of weight matrix is [10][2500]. So everyweight values could have 2500 pixels for each 10 classes. We can easily reshape and make an  grayscale image of weights for each output class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a909497d-2cb8-4dd6-933e-ffe266c5dc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for visualizing weights of each output class\n",
    "def visualize_weights(parameters):\n",
    "    for i in range(c):\n",
    "        weight_best = parameters[\"w\"][0][i].reshape((img_size, img_size))\n",
    "        plt.imshow(weight_best, cmap='gray', vmin=np.amin(weight_best), vmax=np.amax(weight_best))\n",
    "        plt.savefig(str(i)+\".png\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fa9ee1-cb6f-459a-b32b-aa6449e1f41b",
   "metadata": {},
   "source": [
    "### **Helper functions for data**\n",
    "\n",
    "Here are some functions for reading from image data and creating proper data structers from them. After that we need to flatten the image data and normalize the values to 0-1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba5db111-9989-4f2a-9b8a-54aa83e68895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function takes all the images urls and their class (which animal)\n",
    "# creates a new csv file which has urls\n",
    "def all_image_urls_to_csv():\n",
    "    folder_names = os.listdir('../Project/raw-img')\n",
    "    category = []\n",
    "    files = []\n",
    "    for k, folder in enumerate(folder_names):\n",
    "        filenames = os.listdir(\"../Project/raw-img/\" + folder)\n",
    "        for file in filenames:\n",
    "            files.append(\"../Project/raw-img/\" + folder + \"/\" + file)\n",
    "            category.append(k)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'filename': files,\n",
    "        'category': category\n",
    "    })\n",
    "    train_df = pd.DataFrame(columns=['filename', 'category'])\n",
    "    for i in range(10):\n",
    "        train_df = train_df.append(df[df.category == i].iloc[:, :])\n",
    "\n",
    "    df.to_csv('out.csv', index=False)\n",
    "    return train_df\n",
    "\n",
    "\n",
    "# \n",
    "def create_data(data, url_category_data, start_index, finish_index):\n",
    "    data = []\n",
    "    for i in range(start_index, finish_index):\n",
    "        path = url_category_data[i][0]\n",
    "        target = url_category_data[i][1]\n",
    "        try:\n",
    "            img_array = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "            new_img_array = cv2.resize(img_array, (img_size, img_size))\n",
    "            data.append([new_img_array, target])\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return data\n",
    "\n",
    "\n",
    "def flatten_and_normalize_data(data, start_index, end_index):\n",
    "    for i in range(start_index, end_index):\n",
    "        arr = np.asarray(data[i][0])\n",
    "        data[i][0] = arr.reshape((img_size * img_size,)).astype(np.float32)\n",
    "        data[i][0] = (data[i][0] / 255)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2f538a-d6b7-4f38-b1b3-a0d8de80fca0",
   "metadata": {},
   "source": [
    "### **Train and Validation**\n",
    "\n",
    "In these part of the code, we first train and then validate data for each epoch. In each epoch we creaye mini-batches of changing size(16-32-64-128) and train the parameters with those mini-batches.  After all batches in train data is completed once, one epoch is finished.\n",
    "After one epoch, validation data is used for measuring the performance after training that epoch. When the validation data has the best performance, we keep that parameters to use in the test set. The reason we do that is to deal with overfitting problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8870015d-47fa-4713-98b1-9843685517e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_amd_validation(x_train, y_train, x_validation, y_validation, url_category_data, learning_rate):\n",
    "    parameters = init_parameters()\n",
    "    cost_list = []\n",
    "    validation_cost_list = []\n",
    "    start_learning_rate = learning_rate\n",
    "\n",
    "    best_parameters_from_validation = parameters\n",
    "    best_performance_from_validation = 0\n",
    "    train_performance_list = []\n",
    "    validation_performance_list = []\n",
    "\n",
    "    for i in range(epoch):  # epoch\n",
    "        data = []\n",
    "        performance_val_train = 0\n",
    "        for j in range(0, total_train_image_count, batch_size):  # batch\n",
    "            data = create_data(data, url_category_data, j, j + batch_size)\n",
    "            data = flatten_and_normalize_data(data, 0, batch_size)\n",
    "            x_train, y_train = init_train(data, x_train, y_train)\n",
    "\n",
    "            activation_funcs = forward_propagation(x_train, parameters)\n",
    "            cost = cost_function(activation_funcs[-1], y_train)\n",
    "            perf_t = performance(activation_funcs[-1], y_train)\n",
    "            performance_val_train += perf_t\n",
    "            parameters = backward_prop(x_train, y_train, parameters, activation_funcs)\n",
    "\n",
    "        cost_list.append(cost)\n",
    "        performance_val_train = performance_val_train / (total_train_image_count / batch_size)\n",
    "        train_performance_list.append(performance_val_train)\n",
    "        print(\"Cost after\", i, \"epoch is :\", cost)\n",
    "        print(\"------------------------------------------------\")\n",
    "\n",
    "        performance_val = 0\n",
    "        for k in range(total_train_image_count, total_train_image_count + total_validation_image_count, batch_size):\n",
    "            validation_data = []\n",
    "            validation_data = create_data(validation_data, url_category_data, k, k + batch_size)\n",
    "            validation_data = flatten_and_normalize_data(validation_data, 0, batch_size)\n",
    "            x_validation, y_validation = init_train(validation_data, x_validation, y_validation)\n",
    "            activation_funcs_v = forward_propagation(x_validation, parameters)\n",
    "            cost_v = cost_function(activation_funcs_v[-1], y_validation)\n",
    "            perf = performance(activation_funcs_v[-1], y_validation)\n",
    "            performance_val += perf\n",
    "        validation_cost_list.append(cost_v)\n",
    "        print(\"Validation Cost :\", cost_v)\n",
    "        performance_val = performance_val / (total_validation_image_count / batch_size)\n",
    "        validation_performance_list.append(performance_val)\n",
    "        print(\"Performance : \", performance_val)\n",
    "        if performance_val >= best_performance_from_validation:\n",
    "            best_performance_from_validation = performance_val\n",
    "            print(\"BEST PERFORMANCE FOR NOW : \", best_performance_from_validation)\n",
    "            best_parameters_from_validation = parameters\n",
    "        print(\"--------------------------------------------------------------------\")\n",
    "\n",
    "        learning_rate *= 0.95\n",
    "\n",
    "    plt.title(\n",
    "        \"TRAIN DATA \\n\" + \"Hidden Layer Count:\" + str(hidden_layer_count) + \"-- Learning Rate:\" + str(\n",
    "            start_learning_rate) + \"-- Batch:\" + str(batch_size))\n",
    "    plt.plot(np.arange(0, len(cost_list)), cost_list, label=\"test\")\n",
    "    plt.plot(np.arange(0, len(validation_cost_list)), validation_cost_list, label=\"validation\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cost.png\")\n",
    "    plt.show()\n",
    "\n",
    "    plt.title(\"VALIDATION DATA \\n\" + \"Hidden Layer Count:\" + str(hidden_layer_count) + \"-- Learning Rate:\" + str(\n",
    "        start_learning_rate) + \"-- Batch:\" + str(batch_size))\n",
    "    plt.plot(np.arange(0, len(train_performance_list)), train_performance_list, label=\"train\")\n",
    "    plt.plot(np.arange(0, len(validation_performance_list)), validation_performance_list, label=\"validation\")\n",
    "    plt.ylabel(\"Performance\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"performance.png\")\n",
    "    plt.show()\n",
    "    return best_parameters_from_validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d044344e-25b4-4eeb-b012-4b38dcf486e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(learning_rate=learning_rate):\n",
    "    train_df = all_image_urls_to_csv()\n",
    "    url_category_data = np.array(train_df.iloc[:, :])\n",
    "    np.random.seed(101)\n",
    "    np.random.shuffle(url_category_data)\n",
    "\n",
    "    x_train = np.zeros((n, batch_size))\n",
    "    y_train = np.zeros((c, batch_size))\n",
    "\n",
    "    x_validation = np.zeros((n, batch_size))\n",
    "    y_validation = np.zeros((c, batch_size))\n",
    "\n",
    "    x_test = np.zeros((n, batch_size))\n",
    "    y_test = np.zeros((c, batch_size))\n",
    "\n",
    "    parameters = train_amd_validation(x_train, y_train, x_validation, y_validation, url_category_data, learning_rate)\n",
    "    np.save(\"parameters.npy\", parameters)\n",
    "\n",
    "    test_data = []\n",
    "    performance_test = 0\n",
    "    start = total_train_image_count + total_validation_image_count\n",
    "    for j in range(start, start + total_test_image_count, batch_size):\n",
    "        test_data = create_data(test_data, url_category_data, j, j + batch_size)\n",
    "        test_data = flatten_and_normalize_data(test_data, 0, batch_size)\n",
    "        x_test, y_test = init_train(test_data, x_test, y_test)\n",
    "\n",
    "        activation_funcs_t = forward_propagation(x_test, parameters)\n",
    "        perf = performance(activation_funcs_t[-1], y_test)\n",
    "        performance_test += perf\n",
    "    performance_test = performance_test / (total_test_image_count / batch_size)\n",
    "    print(\"TEST PERFORMANCE\", performance_test)\n",
    "\n",
    "    if hidden_layer_count == 0:\n",
    "        visualize_weights(parameters)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7ead0-ecda-4df2-b705-03435f9340c4",
   "metadata": {},
   "source": [
    "# **Analysis of Part1**\n",
    "---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643925f-7b4b-4a2d-b742-f849189b4dbf",
   "metadata": {},
   "source": [
    "For analysis of part1 we change some parameters and try to observe the outcomes. Here is some example graph. We set the parameters as:\n",
    "\n",
    "|  | Values | \n",
    "| --- | --- |\n",
    "| Hidden Layer Count | 1 |\n",
    "| Activation Function |  tanh |\n",
    "| Batch Size | 32 |\n",
    "| Learning Rate | 0.02 |\n",
    "| Accuracy | 32,17 |\n",
    "\n",
    "Our accuracy in the trials are not so high and we think this is because of low epoch counts we use because we can see the increasing performance and decreasing cost between epochs. So we think if our computers are little bit better and we can run more epochs in suitable timeline, we can see higher accuracy rates. There is an example graph.\n",
    "\n",
    "P.S.= I accidentally write \"test\" on the label of the train data sets cost graph. In all graphs, when you see the word \"test\", we tried to mean \"train\".\n",
    "\n",
    "<img src=./hiddenlayer_1/tan/b32_lr0,02/cost.png width=400>\n",
    "\n",
    "As we can see the cost of test set and train set is decreasing simultaneously as we train the neural network. We use validation to choose best parameters because we expect overfitting with train data. But in this case we didn't see any overfitting, we think it is because of low epoch count. If we keep training, parameters should be overfit in some point. But besides that, we can see that our cost is decreasing properly, therefore the performance is increasing. You can see performance graph below.\n",
    "\n",
    "<img src=./hiddenlayer_1/tan/b32_lr0,02/performance.png width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fcdbd7-a3f7-4efc-869e-ae473009c983",
   "metadata": {},
   "source": [
    "### **1. Effects of Changing Hidden Layer**\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac661f0d-01f7-4794-8ca9-9646cf7af57b",
   "metadata": {},
   "source": [
    "* **Single Layer Neural Network**\n",
    "\n",
    "In single layer neural networks, there is only one inout layer and one output layer. The activation function for output layer is softmax function. As we can see from the cost and performance graphs, while the cost of train data set is constanly decreasing, the performance increases. And also from the cost graphic, we see the validation set's cost, it first decreases but at some point it started to increase. That point could be the time when overfitting starts. In our implementation when overfitting starts, we store the best parameters for test set. So when overfitting starts, our paraneters stops updating actually. So in this example the best parameters are selected from epoch 5 to 10 where the overfitting just starts.\n",
    "\n",
    "| | Accuracy|\n",
    "| -- | -- |\n",
    "| 0 hidden layer test set | 26,27|\n",
    "\n",
    "<img src=./hiddenlayer_0/b32_lr0,01/cost.png width=300> <img src=./hiddenlayer_0/b32_lr0,01/performance.png width=300>\n",
    "\n",
    "\n",
    "* **1 Layer Neural Network**\n",
    "\n",
    "In 1 layer neural networks, there is one input layer, 1 hidden layer and one output layer. The activation function for hidden layer is tanh function and for output it is softmax function. As we can see from the cost and performance graphs, while the cost of train data set is constanly decreasing, the performance increases\n",
    "\n",
    "| | Accuracy|\n",
    "| -- | -- |\n",
    "| 1 hidden layer test set | 29,11 |\n",
    "\n",
    "<img src=./hiddenlayer_1/tan/b32_lr0,01/cost.png width=300> <img src=./hiddenlayer_1/tan/b32_lr0,01/performance.png width=300>\n",
    "\n",
    "* **2 Layer Neural Network**\n",
    "\n",
    "In 2 layer neural networks, there is one input layer, 2 hidden layers and one output layer. The activation function for hidden layers are tanh function and for output it is softmax function. From the graphs we see that there wasn't much change between the epoch after epoch5. We think that is a problem.\n",
    "\n",
    "| | Accuracy|\n",
    "| -- | -- |\n",
    "| 2 hidden layer test set | 18,25 |\n",
    "\n",
    "<img src=./hiddenlayer_2/tan/b32_lr0,02/cost.png width=300> <img src=./hiddenlayer_2/tan/b32_lr0,02/performance.png width=300>\n",
    "\n",
    "**Overall**\n",
    "As we can see, the performance of 1 hidden layer is the best one. After that single neural network works well too. We think that may be because when there is one hidden layer, it was perfectly learn what it needs to learn.In 1 hidden layer situation our neural network works well and learn more than the others. Most of the best accuracy vvalues are come from 1 hidden layer trials. And when there is more layers, that could fall into the problem of overfitting. And also no hidden layer approach is not a bad approach for our case ı think. It directky classifies by the weights and biasses that learned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f44b6-1005-40b1-9467-23642a30a1af",
   "metadata": {},
   "source": [
    "### **2. Effects of Activation Functions**\n",
    "----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d5250-5977-4787-8776-7404c6e64ee6",
   "metadata": {},
   "source": [
    "* **Sigmoid**    $y=\\frac{1}{1+ e^(-x)}$\n",
    "* **Tanh**       $y=tanh(x)$\n",
    "* **Relu**       $y=max(0,x)$\n",
    "\n",
    "This time we create our networks with different activation functions in hidden layers. Below you can see the accuracy of each neural network and also cost/performance graphics of each trial. In the trials everything is constant but the activation functions.\n",
    "\n",
    "Graphics are given with this order: \n",
    "1. 1 Layer, Batch Size=64 , Learning Rate=0.01, Activation Function = Sigmoid\n",
    "2. 1 Layer, Batch Size=64 , Learning Rate=0.01, Activation Function = Tanh\n",
    "3. 1 Layer, Batch Size=64 , Learning Rate=0.01, Activation Function = Relu\n",
    "\n",
    "The accuracy values of each trial:\n",
    "\n",
    "| Hidden Layer Count |Activation Function| Learning Rate | Batch Size | **Test Accuracy** |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1  | sigmoid |0.01 | 32 | 22 |\n",
    "| 1  | tanh |0.01 | 32 | 26,56 |\n",
    "| 1  | relu |0.01 | 32 | 29,50 |\n",
    "\n",
    "\n",
    "\n",
    "**Cost Graphics of Trials**\n",
    "\n",
    "1. <img src=./hiddenlayer_1/sigmoid/b32_lr0,01/cost.png width=300> \n",
    "2. <img src=./hiddenlayer_1/tan/b64_lr0,01/cost.png  width=300>              \n",
    "3. <img src=./hiddenlayer_1/relu/b64_lr0,01/cost.png  width=300> \n",
    "\n",
    "**Performance Graphics of Trials**\n",
    "\n",
    "1. <img src=./hiddenlayer_1/sigmoid/b32_lr0,01/performance.png width=300>\n",
    "2. <img src=./hiddenlayer_1/tan/b64_lr0,01/performance.png  width=300>            \n",
    "3. <img src=./hiddenlayer_1/relu/b64_lr0,01/performance.png  width=300> \n",
    "\n",
    "\n",
    "As we can see from the graphs and accuracy values, Relu is the best and then tanh. The worst activation function amongst them is sigmoid. In sigmoid function and tanh function there is vanishing gradient problem. In those functions the problem arises when a large input space is mapped to a small one, causing the derivatives to disappear. Because of that sigmoid and tanh functions doesn't work well in our dataset.\n",
    "\n",
    "The advantages of the relu function is, maximum Threshold values are infinity, so there is no issue of Vanishing Gradient problem so the output prediction accuracy and there efficiency is maximum an speed is fast compare to other activation functions.\n",
    "\n",
    "The performances in our trials, support those issues. We can say relu is the best activation function for us."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da895e8e-1a21-4ee5-a0a1-c0c36dbf15bc",
   "metadata": {},
   "source": [
    "### **3. Effect of Changing Batch Size**\n",
    "---------------------------------------------------------------------------------\n",
    "\n",
    "For a one layer neural network, we create our networks with different batch sizes. Below you can see the accuracy of each neural network and also cost/performance graphics of each trial.\n",
    "In the trials everything is constant but the batch size. The batch sizes changes from the values 16-32-64-128. \n",
    "\n",
    "Graphics are given with this order: \n",
    "1. 1 Layer, Learning Rate=0.01, Batch Size=16\n",
    "2. 1 Layer, Learning Rate=0.01, Batch Size=32\n",
    "3. 1 Layer, Learning Rate=0.01, Batch Size=64\n",
    "4. 1 Layer, Learning Rate=0.01, Batch Size=128\n",
    "\n",
    "The accuracy values of each trial:\n",
    "\n",
    "| Hidden Layer Count |Activation Function| Learning Rate | Batch Size | **Test Accuracy** |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1  | tanh |0.01 | 16 | 31 |\n",
    "| 1  | tanh |0.01 | 32 | 29 |\n",
    "| 1  | tanh |0.01 | 64 | 26 |\n",
    "| 1  | tanh |0.01 | 128 | 21 |\n",
    "\n",
    "\n",
    "\n",
    "**Cost Graphics of Trials**\n",
    "\n",
    "1. <img src=./hiddenlayer_1/tan/b16_lr0,01/cost.png width=300> \n",
    "2. <img src=./hiddenlayer_1/tan/b32_lr0,01/cost.png  width=300>              \n",
    "3. <img src=./hiddenlayer_1/tan/b64_lr0,01/cost.png  width=300> \n",
    "4. <img src=./hiddenlayer_1/tan/b128_lr0,01/cost.png  width=300>\n",
    "\n",
    "\n",
    "**Performance Graphics of Trials**\n",
    "\n",
    "\n",
    "1. <img src=./hiddenlayer_1/tan/b16_lr0,01/performance.png width=300> \n",
    "2. <img src=./hiddenlayer_1/tan/b32_lr0,01/performance.png  width=300>              \n",
    "3. <img src=./hiddenlayer_1/tan/b64_lr0,01/performance.png  width=300> \n",
    "4. <img src=./hiddenlayer_1/tan/b128_lr0,01/performance.png  width=300>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de60d76e-f8e9-4b11-bbf6-11c2a31b1f80",
   "metadata": {},
   "source": [
    "As we can see from the accuracy values of each trial, when the batch size is increasing, our performance is increasing a little bit too. We think this situation happens becuase, in lower batch sizes there were more iterations in each epoch. For example, we did out trials with 30 epoch. In batch size 16, there will be 1280 iterations in each epoch. And in batch size 128 there will be 160 iterations in each epoch. That means in lower batch sizes there will be more updates in each epoch. Since each update aims to find local minima of that value with gradient descent, if we do more updates with proper rates we can get to local minima more quickly. Eventhough small batch sizes have more iteration and more time complexity, they has slightly better performance.\n",
    "\n",
    "From the graphs we can see that smaller batch sizes has more smooth increasing of performance. And also for batch size=16 we can see a little overfitting around the epoch 15. We solve this prolem by choosing he best parameters by validation performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30a0ae6-5301-4d1e-9ee9-aefc4205e07b",
   "metadata": {},
   "source": [
    "### **4. Effect of Changing Learning Rate**\n",
    "---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e15a092-5340-4e46-bda4-185a440d6ef9",
   "metadata": {},
   "source": [
    "This time we create our networks with different learning rates. Below you can see the accuracy of each neural network and also cost/performance graphics of each trial. In the trials everything is constant but the learning  rates. The learning rates changes from the values 0,02 - 0,01 - 0,005. \n",
    "\n",
    "Graphics are given with this order: \n",
    "1. 1 Layer, Batch Size=32 , Learning Rate=0.02\n",
    "2. 1 Layer, Batch Size=32 , Learning Rate=0.01\n",
    "3. 1 Layer, Batch Size=32 , Learning Rate=0.005\n",
    "\n",
    "The accuracy values of each trial:\n",
    "\n",
    "| Hidden Layer Count |Activation Function| Learning Rate | Batch Size | **Test Accuracy** |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| 1  | tanh |0.02 | 32 | 32 |\n",
    "| 1  | tanh |0.01 | 32 | 29 |\n",
    "| 1  | tanh |0.005 | 32 | 27 |\n",
    "\n",
    "\n",
    "\n",
    "**Cost Graphics of Trials**\n",
    "\n",
    "1. <img src=./hiddenlayer_1/tan/b32_lr0,02/cost.png width=300> \n",
    "2. <img src=./hiddenlayer_1/tan/b32_lr0,01/cost.png  width=300>              \n",
    "3. <img src=./hiddenlayer_1/tan/b32_lr0,05/cost.png  width=300> \n",
    "\n",
    "**Performance Graphics of Trials**\n",
    "\n",
    "1. <img src=./hiddenlayer_1/tan/b32_lr0,02/performance.png width=300> \n",
    "2. <img src=./hiddenlayer_1/tan/b32_lr0,01/performance.png  width=300>              \n",
    "3. <img src=./hiddenlayer_1/tan/b32_lr0,05/performance.png  width=300> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc8f3f5-26c3-4257-9c5b-a3e8fdd64f92",
   "metadata": {},
   "source": [
    "As we can see from the accuracy values, bigger learning rate has better performance. Actually we know that if the learning rate is too high, the gradient descent can overshoot the minimum and it may fail to converge. But also if the learning rate is too small, gradient descent is small and it takes so much time, iterations to reach miinimum. Both ways is bad for us. \n",
    "As we can see from the trials, the best performance is when the learning rate is 0,02 which is highest in our trials. It means it is not too high for our data. But from the cost graphics we can say that learning rate 0,005 is too small because in 30 epochs the cost is not decreases as much as we wanted to.\n",
    "From our outputs and graphs we say that learning rate 0,02 is the better choice amongst others. It has better capability to reduce cost in more faster way and it does noy misses any minimum as we can see. And for preventing this we also reduce the learning rate by multiplying it by a decay rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbb9f6f-8d08-453e-8e6a-d86129c8808b",
   "metadata": {},
   "source": [
    "## **Visualizing Parameters**\n",
    "\n",
    "Weight matrix of **butterfly** output class:\n",
    "\n",
    "<img src=./visualization/4.png width=300>\n",
    "\n",
    "Weight matrix of **elephant** output class:\n",
    "\n",
    "<img src=./visualization/6.png width=300> \n",
    "\n",
    "Weight matrix of **chicken** output class:\n",
    "\n",
    "<img src=./visualization/5.png width=300> \n",
    "\n",
    "Weight matrix of **spider** output class:\n",
    "\n",
    "<img src=./visualization/2.png width=300> \n",
    "\n",
    "Those images of weight matrices are taken from single layer neural networks. The reason behind this is tho get an same image size with the weight matrix. And also images are more precise when de the epoch size is decreasing. If the epoch size is too high most of the images looks like this:\n",
    "\n",
    "A butterfly when epoch is much higher:\n",
    "\n",
    "<img src=./hiddenlayer_0/b32_lr0,01/4.png width=300> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af83e822-58fc-4a33-80db-6160982488e2",
   "metadata": {},
   "source": [
    "# **PART 2**\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16066c-2a95-4d9b-97cf-6d2d96f77d75",
   "metadata": {},
   "source": [
    "### **Convulational Neural Network**\n",
    "\n",
    "Convolutional Neural Network (CNN) is an neural network which extracts or identifies a feature in a particular image. CNN has the following five basic components:\n",
    "\n",
    "* **Convolution** : to detect features in an image\n",
    "* **ReLU** : to make the image smooth and make boundaries distinct\n",
    "* **Pooling** : to help fix distored images\n",
    "* **Flattening** : to turn the image into a suitable representation\n",
    "* **Full connection** : to process the data in a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c74e9-8353-4f82-8939-fb15e7309928",
   "metadata": {},
   "source": [
    "### **VGG-19**\n",
    "\n",
    "In this part of the assignment, we used pretrained VGG-19 convolutional neural network (CNN) and finetune this network to classify the sample images.\n",
    "Here is the the figure of VGG-19 network architecture:\n",
    "<img src=https://ichi.pro/assets/images/max/724/0*E6BE6GDv-53smX0B.jpg wifth=400>\n",
    "\n",
    "\n",
    "So in simple language VGG is a deep CNN used to classify images.It is a variant of VGG model which in short consists of 19 layers (16 convolution layers, 3 Fully connected layer, 5 MaxPool layers and 1 SoftMax layer). The layers in VGG19 model are as follows:\n",
    "\n",
    "* Conv3x3 (64)\n",
    "* Conv3x3 (64)\n",
    "* MaxPool\n",
    "* Conv3x3 (128)\n",
    "* Conv3x3 (128)\n",
    "* MaxPool\n",
    "* Conv3x3 (256)\n",
    "* Conv3x3 (256)\n",
    "* Conv3x3 (256)\n",
    "* Conv3x3 (256)\n",
    "* MaxPool\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* MaxPool\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* Conv3x3 (512)\n",
    "* MaxPool\n",
    "* Fully Connected (4096)\n",
    "* Fully Connected (4096)\n",
    "* Fully Connected (1000)\n",
    "* SoftMax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-dancing",
   "metadata": {},
   "source": [
    "### **Initializing Parameters**\n",
    "Before starting, we should initialize some parameters like batch size, epoch number, learning rate etc. and do necessary imports. And we have translate dictionary which is for translation of image class to animal name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "expressed-saver",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.functional import split\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from collections import OrderedDict\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import ConcatDataset, DataLoader, Subset\n",
    "\n",
    "translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\",\n",
    "             \"gallina\": \"chicken\", \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \n",
    "             \"ragno\": \"spider\", \"scoiattolo\": \"squirrel\" }\n",
    "\n",
    "classes = [\"cane\", \"cavallo\", \"elefante\", \"farfalla\", \"gallina\", \"gatto\", \"mucca\", \"pecora\",\"ragno\", \"scoiattolo\" ]\n",
    "\n",
    "batch_size = 60\n",
    "disimage = 20\n",
    "epoch = 0\n",
    "learning_rate = 0.005\n",
    "is_all_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "written-transfer",
   "metadata": {},
   "source": [
    "### Initializing Data\n",
    "\n",
    "Here we get the images and transform them with different filters like rotation and resize. With max_length variable we choose how many images we want to get from each image class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "equipped-accused",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_data():\n",
    "    for dirname, _, filenames in os.walk('./raw-img'):\n",
    "        for filename in filenames:\n",
    "            path, folder = os.path.split(dirname)\n",
    "\n",
    "    data_transform = transforms.Compose([transforms.RandomRotation(45),\n",
    "                                          transforms.RandomRotation(30),\n",
    "                                          transforms.RandomResizedCrop(1080),\n",
    "                                          transforms.Resize(512),\n",
    "                                          transforms.Resize(224),\n",
    "                                          transforms.RandomRotation(45),\n",
    "                                          transforms.ToTensor()])\n",
    "\n",
    "    dataset = datasets.ImageFolder(path, transform=data_transform)\n",
    "\n",
    "    max_length = 15\n",
    "    idx = [i for i in range(len(dataset)) if dataset.imgs[i][1] == dataset.class_to_idx[dataset.classes[0]]]\n",
    "    subset = Subset(dataset, idx)\n",
    "    data = Subset(subset, idx[:max_length])\n",
    "\n",
    "    for j in range(1, 10):\n",
    "        idx = [i for i in range(len(dataset)) if dataset.imgs[i][1] == dataset.class_to_idx[dataset.classes[j]]]\n",
    "        subset = Subset(dataset, idx[:max_length])\n",
    "        data = ConcatDataset((data, subset))\n",
    "        print(len(data))\n",
    "\n",
    "    return data\n",
    "\n",
    "# dataset = initialize_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-sending",
   "metadata": {},
   "source": [
    "### Splitting the Data\n",
    "\n",
    "In split_data function we randomly shuffle the dataset and split it to train, validation and test sets. Then we load them to DataLoader of PyTorch for model to be able to work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "plain-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(dataset_length, validation_size=0.1, test_size=0.1):\n",
    "    indices = [i for i in range(dataset_length)]\n",
    "    np.random.shuffle(indices)\n",
    "    validation_dataset = int(np.floor((validation_size) * dataset_length))\n",
    "    test_dataset = int(np.floor((validation_size+test_size) * dataset_length))\n",
    "    validation_idx, test_idx, train_idx = indices[:validation_dataset], indices[validation_dataset:test_dataset], indices[test_dataset:]\n",
    "    return validation_idx, test_idx, train_idx\n",
    "\n",
    "# validation_idx, test_idx, train_idx = split_data(len(dataset), 0.1, 0.1)\n",
    "\n",
    "# train_loader = DataLoader(Subset(dataset, train_idx), batch_size=batch_size)\n",
    "# valid_loader = DataLoader(Subset(dataset,validation_idx), batch_size=batch_size)\n",
    "# test_loader = DataLoader(Subset(dataset,test_idx), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rolled-economy",
   "metadata": {},
   "source": [
    "### Creating the Model\n",
    "\n",
    "To create our model we use PyTorch. With PyTorch you can use models.vgg19 to use VGG-19. We specify the classifier filters and attach it to our model. With is_all_grad boolean we finetune all parameters or just finetune the last 2 of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broke-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(is_all_grad=True):\n",
    "    model = models.vgg19(pretrained=True)\n",
    "    model.cu\n",
    "    classifier = nn.Sequential(OrderedDict([('fc1', nn.Linear(25088, 6000)), ('relu', nn.ReLU()), ('dropout', nn.Dropout(.5)), ('fc2', nn.Linear(6000, 10)), ('output', nn.Softmax(dim=1) )]))        \n",
    "    model.classifier = classifier\n",
    "\n",
    "    if(not is_all_grad):\n",
    "        for name, param in model.named_parameters():\n",
    "            print(name, param.size())\n",
    "            param.requires_grad = False\n",
    "\n",
    "        for name, param in model.named_parameters():\n",
    "            if(name == \"classifier.fc1.weight\" or name == \"classifier.fc1.bias\" or name == \"classifier.fc2.weight\" or name == \"classifier.fc2.bias\"):\n",
    "                print(name)\n",
    "                print(param.requires_grad)\n",
    "                param.requires_grad = True\n",
    "                print(param.requires_grad)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "# model = create_model(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-consortium",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "Here we specify our optimizer, loss function and function which trains the model. In function we get images with batches, train the model with images and do backward propagation. Last we calculate correct classses, total classes and train loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bigger-globe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "\n",
    "def seq(model, df, name):\n",
    "    train_loss = 0.0\n",
    "    class_correct = list(0. for i in range(10))\n",
    "    class_total = list(0. for i in range(10))\n",
    "\n",
    "    for batch_i, (data, target) in enumerate(df):\n",
    "        print(\"Batch \" + str(batch_i) + \":\")\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = model(data)\n",
    "        # calculate the batch loss\n",
    "        loss = loss_function(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        if name == 'train': \n",
    "            loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss \n",
    "        train_loss += loss.item()\n",
    "        _, pred = torch.max(output, 1) \n",
    "        # compare predictions to true label\n",
    "        correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "        correct = np.squeeze(correct_tensor.numpy())\n",
    "        for i in range(len(target.data)):\n",
    "            label = target.data[i]\n",
    "            class_correct[label] += correct[i].item()\n",
    "            class_total[label] += 1\n",
    "        \n",
    "    return class_correct, class_total, train_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-bristol",
   "metadata": {},
   "source": [
    "### Printing the Data\n",
    "\n",
    "We print the loss, accuracy for each epoch. Also we collect the loss and accuracy values for plotting graph later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verbal-handle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printdata(class_correct, class_total, train_loss, epoch, name, df, loss_values, accuracy_values):\n",
    "    loss = train_loss / len(df)\n",
    "    accuracy = 100.0 * np.sum(class_correct) / np.sum(class_total)\n",
    "    \n",
    "    print(\"Epoch \", epoch, \"loss: \", loss, \"\\t\", name, \" Accuracy(Overall): \", accuracy, \"(\", np.sum(class_correct), \"/\", np.sum(class_total), \")\")\n",
    "    #delete later\n",
    "    for i in range(10):\n",
    "        if class_total[i] > 0:\n",
    "            print(f'{name} Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
    "            translate[classes[i]], 100 * class_correct[i] / class_total[i],\n",
    "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
    "\n",
    "    loss_values.append(loss)\n",
    "    accuracy_values.append(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-drill",
   "metadata": {},
   "source": [
    "### Plotting the Loss and Accuracy Graph\n",
    "\n",
    "Here we plot the epoch-cost and epoch-accuracy graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "trying-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_accuracy(train_loss_values, train_accuracy_values, validation_loss_values, validation_accuracy_valeus):\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.title(\"TRAIN DATA \\n\" + \"-- Learning Rate:\" + str(learning_rate) + \"-- Batch:\" + str(batch_size))\n",
    "    plt.plot(np.arange(0, len(train_loss_values)), train_loss_values, label=\"train\")\n",
    "    plt.plot(np.arange(0, len(validation_loss_values)), validation_loss_values, label=\"validation\")\n",
    "    plt.ylabel(\"Cost\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"cost.png\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.title(\"TRAIN DATA \\n\" + \"-- Learning Rate:\" + str(learning_rate) + \"-- Batch:\" + str(batch_size))\n",
    "    plt.plot(np.arange(0, len(train_accuracy_values)), train_accuracy_values, label=\"train\")\n",
    "    plt.plot(np.arange(0, len(validation_accuracy_valeus)), validation_accuracy_valeus, label=\"validation\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend()\n",
    "    plt.savefig(\"accuracy.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "light-spirit",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "\n",
    "In above seq function we train the model with many batches in one epoch. Here we use that seq function and use more epochs. Also we validate our model with validation dataset to see whether our model is overfit or not. Last we save the model for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "economic-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, train_loader,valid_loader, num_epochs=1):\n",
    "    train_loss_values = []\n",
    "    train_accuracy_values = []\n",
    "    validation_loss_values = []\n",
    "    validation_accuracy_values = []\n",
    "\n",
    "    # number of epochs to train the model\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        class_correct = list(0. for i in range(10))\n",
    "        class_total = list(0. for i in range(10))\n",
    "        # train the model\n",
    "        # Repeat for each batch in the training set\n",
    "        model.train()\n",
    "        class_correct, class_total, train_loss= seq(model,  train_loader, 'train')\n",
    "        printdata(class_correct, class_total, train_loss, epoch, 'train', train_loader, train_loss_values, train_accuracy_values)\n",
    "        # Repeat for each validation batch \n",
    "        model.eval()\n",
    "        class_correct, class_total, train_loss= seq(model, valid_loader, 'validation')\n",
    "        printdata(class_correct, class_total, train_loss, epoch, 'validation', valid_loader, validation_loss_values, validation_accuracy_values)\n",
    "\n",
    "    plot_loss_and_accuracy(train_loss_values, train_accuracy_values, validation_loss_values, validation_accuracy_values)\n",
    "    torch.save(model.state_dict(), 'model.pt')     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comic-aspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainModel(model, train_loader,valid_loader,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "necessary-movement",
   "metadata": {},
   "source": [
    "### Testing the Model\n",
    "\n",
    "Here we use our test dataset to calculate our models accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "inner-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(model, test_loader):\n",
    "    test_loss = 0.0\n",
    "    class_correct = [0. for i in range(10)]\n",
    "    class_total = [0. for i in range(10)]\n",
    "    model.eval()\n",
    "    class_correct, class_total, train_loss= seq(model, test_loader, 'test')\n",
    "    printdata(class_correct, class_total, train_loss, 1, 'test', test_loader, [], [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-pennsylvania",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "Since we have limited resources to train our model we only be able to train our model with 10 epoch and 1000 image from each class which means 10000 images. Because of that our accuracy values may not be look high but it's promising.\n",
    "\n",
    "### 1 - Finetune the weights of all layers in the VGG-19 network\n",
    "\n",
    "| Description | Dog | Horse | Elephant | Butterfly | Chicken | Cat | Cow | Sheep | Spider | Squirrel |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Validation | %89 | %48 | %62 | %86 | %69 | %26 | %38 | %58 | %73 | %53 |\n",
    "|  | (88/98) | (45/93) | (73/117) | (100/116) | (72/103) | (24/89) | (34/88) | (68/117) | (66/90) | (48/89) | \n",
    "| Test | %91 | %55 | %65 | %87 | %79 | %23 | %47 | %60 | %78 | %48 |\n",
    "|  |  (83/91) | (62/112) | (57/87) | (97/111) | (71/89) | (21/91) | (59/124) | (59/98) | (82/104) | (45/93) |\n",
    "\n",
    "We can see that our accuracy values are nor high or low. This can be happen because of small image number or small epoch count.\n",
    "\n",
    "<img src=./visualization/part1.png width=500>\n",
    "\n",
    "If we look to graphs we can see that our cost decreases and accuracy increases. This graph shows our model is works well and promising and if we had better computing power we could achieve bigger accuracy in our model. From view point of graph maybe we can say that after Epoch 8 our model overfits because cost of train decreases and cost of validation increases and accuracy of train increases and accuracy of validation decreases. Also this might be little problem and we might achieve better accuracy with more epoch count.\n",
    "\n",
    "<img src=./visualization/vgg19_output.png width=1000>\n",
    "\n",
    "If we select randomly 20 images from our test data we can see that 15 out of 20 are correct. For some images we can see that even with correct labels images are hard to predict for example third and eleventh images.\n",
    "\n",
    "\n",
    "### 2 - Finetune the weights of only two last fully connected (FC1 and FC2) layers in the VGG-19 network\n",
    "\n",
    "| Description | Dog | Horse | Elephant | Butterfly | Chicken | Cat | Cow | Sheep | Spider | Squirrel |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| Validation | %45 | %46 | %68 | %76 | %80 | %95 | %42 | %73 | %66 | %63 |\n",
    "|  | (50/109) | (47/102) | (82/120) | (74/97) | (75/93) | (95/99) | (37/87) | (63/86) | (71/107) | (63/100) | \n",
    "| Test | %47 | %46 | %62 | %80 | %77 | %96 | %49 | %73 | %64 | %63 |\n",
    "|  |  (46/97) | (47/102) | (59/95) | (89/110) | (88/113) | (82/85) | (52/106) | (76/104) | (59/92) | (61/96) |\n",
    "\n",
    "When we finetune just last two fully connected layers still our accuracy values are nor high or low. Since the values happen because of small image number or small epoch count we might not be able to see difference between finetuning the all layers or last two fully connected layers.\n",
    "\n",
    "<img src=./visualization/part2.png width=500>\n",
    "\n",
    "In graphs we can see that our cost decreases and accuracy increases. This graph also shows our model is works well and promising and if we had better computing power we could achieve bigger accuracy in our model. With this model our validation dataset performs better between Epoch 4 and Epoch 10. This can be happen because of finetuning but also happen because of the data since we shuffle the data before training the model second time. Since the complexity is higher when finetuning the all weights it might perform better with more data.\n",
    "\n",
    "<img src=./visualization/vgg19_output2.png width=1000>\n",
    "\n",
    "Again we select 20 randomly images from our test data and we see that 15 out of 20 images are correct. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-rental",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
